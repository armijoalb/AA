---
title: "Proyecto Final"
author: 'Juan Alberto Martinez Lopez / Alberto Armijo Ruiz '
date: "27 de mayo de 2017"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Librerías utilizadas.
library("caret")
library("leaps")
library("e1071")
library("ROCR")
library("fastAdaboost")
<<<<<<< HEAD
library(randomForest)
=======
library("adabag")
library("pROC")
library("neuralnet")
>>>>>>> 82b843f07344c0f241c18c248764997eac3cdaf5
set.seed(1)
```


## 1. default of credit card clients Data Set (Clasificación)

La base de datos se centra en el caso de los pagos por defecto de los clientes en Taiwán y compara la precisión predictiva de la probabilidad de incumplimiento entre seis métodos de minería de datos. Desde la perspectiva de la gestión de riesgos, el resultado de la precisión predictiva de la probabilidad estimada de incumplimiento será más valioso que el resultado binario de la clasificación - clientes creíbles o no creíbles. Con la probabilidad real de default como variable de respuesta (Y), y la probabilidad predictiva de default como variable independiente (X), el resultado de regresión lineal simple (Y = A + BX) muestra que el modelo de predicción producido por la red neuronal artificial tiene el mayor coeficiente de determinación. Su intercepción de regresión (A) es cercana a cero, y el coeficiente de regresión (B) a uno. Por lo tanto, entre las seis técnicas de minería de datos, la red neuronal artificial es la única que puede estimar con precisión la probabilidad real de incumplimiento. Dichas caracteristicas son:

Limit_bat: Cantidad de credito bancario dado(en dolares), incluye el credito individual y de su familia.
Sex: genero (0 = mujer, 1 = hombre).
Education: Educación recivida en 4 variables:
  Others: Otros estudios.
  University: Estudios universitarios.
  High school: Estudios preparatoria.
  school: Estudios básicos.
Marriage: Estado marital en 3 variables:
  Married: Casado.
  Single: soltero.
  Others: otros.
Age: Edad.
Pay_1-6: 
Historia del pago anterior. Seguimos los últimos registros de pagos mensuales (de abril a septiembre de 2005) de la siguiente manera: X6 = el estado de pago en septiembre de 2005; X7 = estado de reembolso en agosto de 2005; . . . X11 = el estado de pago en abril de 2005. La escala de medición para el estado de pago es: -1 = pagar debidamente; 1 = retraso de pago de un mes; 2 = retardo de pago por dos meses; . . Unesdoc.unesco.org unesdoc.unesco.org 8 = retardo de pago por ocho meses; 9 = retraso de pago por nueve meses y más.

Bill_Amt1-6: 
Monto del estado de cuenta (dólar NT). X12 = monto del estado de cuenta en septiembre de 2005; X13 = monto del estado de cuenta en agosto de 2005; . . . X17 = monto del estado de cuenta en abril de 2005.
Pay_Amt1-6:
Monto del pago anterior (dólar NT). X18 = cantidad pagada en septiembre de 2005; X19 = cantidad pagada en agosto de 2005; . . X23 = cantidad pagada en abril de 2005.
default payment next month: Variable que aprendemos, basamos si lapersona pagará o no el siguiente mes.


```{r} 
credit_card =  read.csv("default_of_credict_card_clients.csv"
                          , sep=",", header = TRUE, row.names =1)
attach(credit_card)
summary(credit_card)

```

```{r}
set.seed(1)
train = sample (nrow(credit_card), round(nrow(credit_card)*0.7)) 
credit_card.train = credit_card[train,]  
credit_card.test = credit_card[-train,]
```

## 2. Preprocesado de los datos.

Lo primero que queremos hacer es comprobar si hay datos perdidos, y si es así; reemplazaremos el valor perdido.
```{r}
anyNA(credit_card.train)
```
Como  no tenemos ningún dato pérdido, no tendremos que reemplazar los valores. Si hubieramos tenido valores tenido, podríamos haber utilizado la función _knnImputation_ para reemplazar los valores perdidos por los k vecinos mÃ¡s cercanos (normalmente k=3). TambiÃ©n podrÃ?amos utilizar la media como sustituto del valor pÃ©rdido.

Lo siguiente que vamos a hacer es modificar aquellas columnas que separan los datos en variables "clases" como por ejemplo la columna _EDUCATION_, que indica que tipo de estudios tiene cada persona. Por cada tipo en los que los separe, crearemos una nueva columna que indique con 0s y 1s la pertenencia a ese tipo. TambiÃ©n tenemos que realizar este proceso con la columna _MARRIAGE_

```{r}
# Modificamos la columna 2, llamada sex, para dividir los datos en 0=mujer, 1=hombre.
credit_card.train$SEX = ifelse(credit_card.train$SEX == 2, 0, 1)
summary(credit_card.train)
```
```{r}
# TambiÃ©n tenemos que modificar la columna EDUCATION, la dividiremos en cuatro columnas diferentes:
# ed.other, ed.university, ed.high_school, ed.school
ed.other = ifelse(credit_card.train$EDUCATION == 4, 1,0)
ed.university = ifelse(credit_card.train$EDUCATION == 2, 1, 0)
ed.high_school = ifelse(credit_card.train$EDUCATION == 3 | credit_card.train$EDUCATION == 2, 1, 0)
ed.school = ifelse(credit_card.train$EDUCATION == 1 | credit_card.train$EDUCATION == 2 | credit_card.train$EDUCATION == 3, 1, 0)

credit_card.train = cbind(credit_card.train,ed.other, ed.high_school, ed.school, ed.university)

# Borramos la columna EDUCATION.
credit_card.train = credit_card.train[,-which(colnames(credit_card.train) == "EDUCATION")]
summary(credit_card.train)
```

```{r}
# TambiÃ©n tenemos que modificar la columna mariage. Introduciremos tres nueva columnas: marriage.married, marriage.single, marriage.others.
marriage.married = ifelse(credit_card.train$MARRIAGE == 1, 1,0)
marriage.single = ifelse(credit_card.train$MARRIAGE == 2, 1,0)
marriage.others = ifelse(credit_card.train$MARRIAGE == 3, 1,0)

# Introducimos los datos.
credit_card.train = cbind(credit_card.train, marriage.married, marriage.single, marriage.others)

# Borramos la variable MARRIAGE.
credit_card.train = credit_card.train[, -which(colnames(credit_card.train) == "MARRIAGE")]
summary(credit_card.train)
```

TambiÃ©n vamos a cambiar el nombre de la columna _PAY0_ por _PAY1_.
```{r}
colnames(credit_card.train)[which(colnames(credit_card.train)=="PAY_0")]="PAY_1"
summary(credit_card.train)
```


Por Último.
```{r}
# Por Ãºltimo, utilizamos la funciÃ³n preprocess.
trans = preProcess(credit_card.train, c("BoxCox") )
trainTransformado = predict(trans, credit_card.train)
summary(trainTransformado)

```

  
```{r}
# Para hacer mÃ¡s sencillo hacer las transformaciones al conjunto de test, se crearÃ¡n funciones para realizar todo lo anterior.

# FunciÃ³n para comprobar si hay datos pÃ©rdidos y reemplazarlos.
reemplazarCol = function(x){
  # Columna SEX
  x$SEX = ifelse(x$SEX == 2, 0, 1)
  
  # Columna EDUCATION.
  ed.other = ifelse(x$EDUCATION == 4, 1,0)
  ed.university = ifelse(x$EDUCATION == 2, 1, 0)
  ed.high_school = ifelse(x$EDUCATION == 3 | x$EDUCATION == 2, 1, 0)
  ed.school = ifelse(x$EDUCATION == 1 | x$EDUCATION == 2 | x$EDUCATION == 3, 1, 0)
  x = cbind(x,ed.other, ed.high_school, ed.school, ed.university)

  # Borramos la columna EDUCATION.
  x = x[,-which(colnames(x) == "EDUCATION")]
  
  # Columna MARRIAGE.
  marriage.married = ifelse(x$MARRIAGE == 1, 1,0)
  marriage.single = ifelse(x$MARRIAGE == 2, 1,0)
  marriage.others = ifelse(x$MARRIAGE == 3, 1,0)
  
  # Introducimos los datos.
  x = cbind(x, marriage.married, marriage.single, marriage.others)
  
  # Borramos la variable MARRIAGE.
  x = x[, -which(colnames(x) == "MARRIAGE")]
  
  # Cambiamos el nombre de la variables PAY_0.
  colnames(x)[which(colnames(x)=="PAY_0")]="PAY_1"
  x
}

preprocesar = function(x,pred=trans){
  transTest = predict(pred, x)
  transTest
}

prepareTest = function(x){
  tr = reemplazarCol(x)
  tr= preprocesar(x)
  tr
}
```

Por último, vamos a utilizar el filtro PCA para comprobar si todos los datos son relevantes. Si encontramos algún datos redundante , lo eliminaremos de nuestro conjunto de datos. Para saber si un dato es redundante, debemos comprobar si todos los atributos PC (PC1, PC2, ..., PCx) son 0 o muy cercanos a 0; si encontramos algún atributo PC que se aleje de 0, no podemos asegurar que el atributos sea redundante, y por lo tanto no lo podremos quitar.

```{r}
pcaTransformation = prcomp(trainTransformado[,-default.payment.next.month], center=F, scale=F)
pcaTransformation$rotation
```


Según los resultados del filtro PCA, no hay ningún dato que sea redundate. Por lo tanto, no eliminaremos ninguno de los atributos del conjunto de datos.

## Estudio de los parámetros e hiperparámetros.
Vamos a realizar un estudio sobre los parámetros para saber cuáles de ellos son los más importantes. Con los más importantes crearemos los modelos lineales que vamos a ajustar.



```{r}
#modelo_step = glm(default.payment.next.month ~ .,family = gaussian, data=trainTransformado)
#modelo_principal = step(modelo_step)

```
Regsubset

```{r}
muestra_regsubsets = regsubsets(default.payment.next.month ~ ., data = trainTransformado, nvmax = 28, method = "exhaustive")
summary((muestra_regsubsets))
reg.sumary = summary(muestra_regsubsets)
```

```{r}
par(mfrow=c(1,2))
plot(reg.sumary$cp, xlab="number of variables", ylab="cp", type="l")
which.min(reg.sumary$cp)
plot(reg.sumary$bic, xlab="number of variables", ylab="BIC", type="l")
which.min(reg.sumary$bic)
par(mfrow=c(1,1) )
```



```{r}
variablesSignificativasCredit = character()

for(nombre in names(trainTransformado) ){
  pred = trainTransformado[, nombre]
  modelo = lm(trainTransformado$default.payment.next.month~pred)
  p_valor = summary(modelo)$coefficients[,4][2]
  
  if(p_valor < 0.1 && p_valor > 0){
    variablesSignificativasCredit = c(variablesSignificativasCredit, nombre)
  }
  
}

variablesSignificativasCredit
```

# Ajuste de modelos.

Para hacer más sencillo el cálculo del error teniendo un modelo, crearemos funciones para calcular el error, para calcular el conjunto de datos precedidos, y otra que las englobe.


```{r}
# Función para calcular la solución dada una predicción.
calculateSol = function(x){
  prediction.model = rep(0,length(x))
  prediction.model[x >= 0.5] = 1
  
  prediction.model
}

# Función para calcular el Error.
calculateErrorClasification = function(calculated.solution, real.sol){
  er = sum(calculated.solution != real.sol)/length(calculated.solution)
  er
}

# Función que calcula el Error pasándole la predicción.
calculateError = function(model.prediction, labels){
  pred = calculateSol(model.prediction)
  return(calculateErrorClasification(pred, labels))
}
```

Transformamos los valores de test.
```{r}
testTransformado = reemplazarCol(credit_card.test)
testTransformado = predict(trans, testTransformado)
dim(trainTransformado)
dim(testTransformado)
summary(testTransformado)
```


```{r}
m1 = glm(default.payment.next.month~LIMIT_BAL+SEX+PAY_3+PAY_4+PAY_5+PAY_6+BILL_AMT1+BILL_AMT2+BILL_AMT3+PAY_AMT1+PAY_AMT2+PAY_AMT3+PAY_AMT3+PAY_AMT4+PAY_AMT5+PAY_AMT6+ed.other+ed.high_school+ed.school+ed.university+marriage.married+marriage.single, data=trainTransformado, family="binomial")

predtr.m1 = predict(m1, trainTransformado)
Ein.m1 = calculateError(predtr.m1, trainTransformado$default.payment.next.month)
Ein.m1

pred.m1 = predict(m1, testTransformado)
Eout.m1 = calculateError(pred.m1, testTransformado$default.payment.next.month)
Eout.m1
```



```{r}
m2 = glm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, family="binomial")
predtr.m2 = predict(m2, trainTransformado)
Ein.m2 = calculateError(predtr.m2, trainTransformado$default.payment.next.month)
Ein.m2

pred.m2 = predict(m2, testTransformado)
Eout.m2 = calculateError(pred.m2, testTransformado$default.payment.next.month)
Eout.m2
```




```{r}
m3= glm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, family="binomial" )
predtr.m3 = predict(m3, trainTransformado)
Ein.m3 = calculateError(predtr.m3, trainTransformado$default.payment.next.month)
Ein.m3

pred.m3 = predict(m3, testTransformado)
Eout.m3 = calculateError(pred.m3, testTransformado$default.payment.next.month)
Eout.m3
```

Nuestro mejor modelo es el tercer modelo, ya que es el más simple de los 3 y obtiene resultados casi iguales que los anteriores. Calcularemos la curva ROC de este modelo, y también calcularemos el área de esta.

```{r}
linear.model = prediction(pred.m3, testTransformado$default.payment.next.month)
perf = performance(linear.model, "tpr", "fpr")
auc.linear = performance(linear.model, measure = "auc")
print(auc.linear@y.values[[1]])
plot(perf)
```


## Modelos Boosting.
Para crear los modelos del boosting, utilizaremos la biblioteca fastAdaboost, que contiene la función adaboost la cuál implementa el algoritmo adaboost. Uno de los parámetros de este algoritmo indica el número de clasficadores que se van a utilizar para separar los datos de la muestra; probaremos varios números de clasificadores. Nos quedaremos con el clasificador que menor error fuera de la muestra cometa. También calcularemos su curva ROC, y calcularemos cuál es el área de esta.

```{r}
bt1 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, nIter=10)
pred.bt1 = predict(bt1, trainTransformado)
Ein.bt1 = pred.bt1$error
Ein.bt1

predTs.bt1 = predict(bt1, testTransformado)
Eout.bt1 = predTs.bt1$error
Eout.bt1
```

```{r}
bt2 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, nIter=50)
pred.bt2 = predict(bt2, trainTransformado)
Ein.bt2 = pred.bt1$error
Ein.bt2

predTs.bt2 = predict(bt2, testTransformado)
Eout.bt2 = predTs.bt2$error
Eout.bt2
```


```{r}
bt3 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, nIter=5)
pred.bt3 = predict(bt3, trainTransformado)
Ein.bt3 = pred.bt3$error
Ein.bt3

predTs.bt3 = predict(bt3, testTransformado)
Eout.bt3 = predTs.bt3$error
Eout.bt3
```

```{r}
bt4 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, nIter=10)
pred.bt4 = predict(bt4, trainTransformado)
Ein.bt4 = pred.bt4$error
Ein.bt4

predTs.bt4 = predict(bt4, testTransformado)
Eout.bt4 = predTs.bt4$error
Eout.bt4
```

```{r}
bt5 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, nIter=50)
pred.bt5 = predict(bt5, trainTransformado)
Ein.bt5 = pred.bt5$error
Ein.bt5

predTs.bt5 = predict(bt5, testTransformado)
Eout.bt5 = predTs.bt5$error
Eout.bt5
```


```{r}
bt6 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, nIter=5)
pred.bt6 = predict(bt6, trainTransformado)
Ein.bt6 = pred.bt6$error
Ein.bt6

predTs.bt6 = predict(bt6, testTransformado)
Eout.bt6 = predTs.bt6$error
Eout.bt6
```

Como se puede ver, los modelos aportados por la técnica de boosting están obteniendo unos resultados bastante pobres, además, estos nos indican que hay overfitting en todos los modelos. Esto puede ser por varias razones, como que los clasificadores débiles seán demasiado débiles o demasiado complejos; también puede darse si tenemos ruido dentro de la muestra de estudio. Para intentar reducir el error, vamos a transformar los datos normalizando, para intentar reducir el ruido lo máximo posible.

Para ello, utilizaremos la función preProcess, está vez indicandole las transformaciones _BoxCox_, _scale_ y _center_.

```{r}
trans2 = preProcess(credit_card.train, c("BoxCox", "scale", "center") )
trainTransformado2 = predict(trans2 , credit_card.train)

# Para el test.
testTransformado2 = reemplazarCol(credit_card.test)
testTransformado2 = preprocesar(testTransformado2, pred=trans2)
```

Ahora probaremos el modelo de 9 carácterísticas, y comprobaremos si los resultados mejoran.

```{r}
bt7 = real_adaboost(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado2, nIter=50)
pred.bt7 = predict(bt7, trainTransformado2)
Ein.bt7 = pred.bt7$error
Ein.bt7

predTs.bt7 = predict(bt7, testTransformado2)
Eout.bt7 = predTs.bt7$error
Eout.bt7
```

Los resultados obtenidos son casi iguales que los obtenidos anteriormente, lo cuál nos indica que el overfitting no está provocado por ruido. Como modelo final, el cuál utilizaremos para compararlo con otros modelos, será el modelo bt3, el cúal es el más simple, utiliza 5 clasificadores y 9 variables para predecir.

```{r}
print(table(pred.bt3$class, trainTransformado$default.payment.next.month))
```

```{r}
salida.boosting = vector(length = length(predTs.bt3$class))
cero = grep("0", predTs.bt3$class)
salida.boosting[cero] = 0
salida.boosting[-cero] = 1
boosting.model = prediction(salida.boosting, testTransformado$default.payment.next.month)
perf.boost = performance(boosting.model, "tpr", "fpr")
auc.boosting = performance(boosting.model, measure = "auc")
print(auc.boosting@y.values[[1]])
plot(perf.boost)
```

## Modelos Redes Neuronales

Para crear los modelos del Redes Neuronales, utilizaremos la biblioteca neuralnet, que contiene la función neuralnet la cuál implementa el algoritmo backpropagation. Uno de los parámetros de este algoritmo indica el número de capas ocultas  y los nodos que contiene en cada capa que se van a utilizar para separar los datos de la muestra; probaremos con distintas capas. Nos quedaremos con la red que menor error fuera de la muestra cometa. También calcularemos su curva ROC, y calcularemos cuál es el área de esta.

```{r}
# n <- names(trainTransformado)
# f <- as.formula(paste("default.payment.next.month  ~", paste(n[!n %in% "default.payment.next.month"], collapse = " + " )))
nn1 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado)

plot(nn1)

n <- c("PAY_1", "PAY_2", "BILL_AMT1", "LIMIT_BAL","AGE","ed.school","PAY_AMT1","PAY_5","marriage.married")
 
pred.nn1 = compute(nn1,testTransformado[names(testTransformado) %in% n])

pred.nn1_ = pred.nn1$net.result*(max(trainTransformado$default.payment.next.month)-min(trainTransformado$default.payment.next.month))+min(trainTransformado$default.payment.next.month)

test.r = (testTransformado$default.payment.next.month)*(max(trainTransformado$default.payment.next.month)-min(trainTransformado$default.payment.next.month))+min(trainTransformado$default.payment.next.month)

summary((test.r - pred.nn1_)^2)
# pred.nn1 = predict(nn1, trainTransformado)
# Ein.nn1 = pred.nn1$error
# Ein.nn1
# 
# predTs.nn1 = predict(nn1, testTransformado)
# Eout.nn1 = predTs.nn1$error
# Eout.nn1
```
