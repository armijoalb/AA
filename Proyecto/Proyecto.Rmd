---
title: "Proyecto Final"
author: 'Juan Alberto Martinez Lopez / Alberto Armijo Ruiz '
date: "27 de mayo de 2017"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Librerías utilizadas.
library("caret")
library("leaps")
library("e1071")
library("ROCR")
library("randomForest")
library("neuralnet")
library("ada")

set.seed(1)
```


# 1. default of credit card clients Data Set (Clasificación)

## Introducción.

La base de datos se centra en el caso de los pagos por defecto de los clientes en Taiwán y compara la probabilidad de que un usuario pague o no pague según datos de pagos anteriores. Desde la perspectiva de la gestión de riesgos, la peor predicción erronea es considerar que un cliente pagará cuando es falso. Las caracteristicas son:

Limit_bat: Cantidad de credito bancario dado(en dolares), incluye el credito individual y de su familia.
Sex: genero (0 = mujer, 1 = hombre).
Education: Educación recivida en 4 variables:
  Others: Otros estudios.
  University: Estudios universitarios.
  High school: Estudios preparatoria.
  school: Estudios básicos.
Marriage: Estado marital en 3 variables:
  Married: Casado.
  Single: soltero.
  Others: otros.
Age: Edad.
Pay_1-6: Historia del pago anterior. Cada variable es un mes distinto. La escala de medición para el estado de pago es: -1 = pagar debidamente; 1 = retraso de pago de un mes; 2 = retardo de pago por dos meses...
Bill_Amt1-6:Estado de la cuenta actual.
Pay_Amt1-6: Pago realizado en ese mes.
default payment next month: Variable que aprendemos, basamos si la persona pagará o no el siguiente mes.

Nuestro objetivo será intentar conseguir una predicción lo mejor posibles, intentando minimizar los falsos positivos (predecimos que un cliente pagará, pero no este no paga).

## Lectura de la base de datos.

Para la lectura de la base de datos, hemos tenido que trasformar el archivo a .csv y además borrar la primera fila por problemas de lectura.

```{r} 
credit_card =  read.csv("default_of_credict_card_clients.csv"
                          , sep=",", header = TRUE, row.names =1)
attach(credit_card)
summary(credit_card)

```

## Creación de los conjuntos de training y test.

Para el training, utilizaremos el 70% de los datos, y dejaremos el 30% restante para el test.

```{r}
set.seed(1)
train = sample (nrow(credit_card), round(nrow(credit_card)*0.7)) 
credit_card.train = credit_card[train,]  
credit_card.test = credit_card[-train,]
```

## 2. Preprocesado de los datos.

Lo primero que queremos hacer es comprobar si hay datos perdidos, y si es así; reemplazaremos el valor perdido.
```{r}
anyNA(credit_card.train)
```
Como  no tenemos ningún dato pérdido, no tendremos que reemplazar los valores. Si hubieramos tenido valores tenido, podríamos haber utilizado la función _knnImputation_ para reemplazar los valores perdidos por los k vecinos más cercanos (por defecto la función utiliza k=3). También podríamos utilizar la media como sustituto de un valor pérdido.

Lo siguiente que vamos a hacer es modificar aquellas columnas que separan los datos en "clases" como por ejemplo la columna _EDUCATION_, que indica que tipo de estudios tiene cada persona. Por cada tipo en los que los separe, crearemos una nueva columna que indique con 0s y 1s la pertenencia a ese tipo. También tenemos que realizar este proceso con la columna _MARRIAGE_

```{r}
# Modificamos la columna 2, llamada sex, para dividir los datos en 0=mujer, 1=hombre.
credit_card.train$SEX = ifelse(credit_card.train$SEX == 2, 0, 1)
```
```{r}
# También tenemos que modificar la columna EDUCATION, la dividiremos en cuatro columnas diferentes:
# ed.other, ed.university, ed.high_school, ed.school
ed.other = ifelse(credit_card.train$EDUCATION == 4, 1,0)
ed.university = ifelse(credit_card.train$EDUCATION == 2, 1, 0)
ed.high_school = ifelse(credit_card.train$EDUCATION == 3 | credit_card.train$EDUCATION == 2, 1, 0)
ed.school = ifelse(credit_card.train$EDUCATION == 1 | credit_card.train$EDUCATION == 2 | credit_card.train$EDUCATION == 3, 1, 0)

credit_card.train = cbind(credit_card.train,ed.other, ed.high_school, ed.school, ed.university)

# Borramos la columna EDUCATION.
credit_card.train = credit_card.train[,-which(colnames(credit_card.train) == "EDUCATION")]
```

```{r}
# También tenemos que modificar la columna mariage. Introduciremos tres nueva columnas: marriage.married, marriage.single, marriage.others.
marriage.married = ifelse(credit_card.train$MARRIAGE == 1, 1,0)
marriage.single = ifelse(credit_card.train$MARRIAGE == 2, 1,0)
marriage.others = ifelse(credit_card.train$MARRIAGE == 3, 1,0)

# Introducimos los datos.
credit_card.train = cbind(credit_card.train, marriage.married, marriage.single, marriage.others)

# Borramos la variable MARRIAGE.
credit_card.train = credit_card.train[, -which(colnames(credit_card.train) == "MARRIAGE")]
```

También vamos a cambiar el nombre de la columna _PAY0_ por _PAY1_.
```{r}
colnames(credit_card.train)[which(colnames(credit_card.train)=="PAY_0")]="PAY_1"
```


Por último, utilizaremos la función preProcess para aplicar la transformación BoxCox a las variables que tengan una varianza elevada.
```{r}
# Por Último, utilizamos la función preProcess.
trans = preProcess(credit_card.train, c("BoxCox") )
trainTransformado = predict(trans, credit_card.train)
summary(trainTransformado)

```

Para no tener que repetir este mismo proceso cuando vayamos a calcular el error fuera de la muestra de entrenamiento, vamos a crear una función que se encargue directamente de ello.

```{r}
# Para hacer más sencillo hacer las transformaciones al conjunto de test, se crearán funciones para realizar todo lo anterior.

# Función para reemplazar las columnas.
reemplazarCol = function(x){
  # Columna SEX
  x$SEX = ifelse(x$SEX == 2, 0, 1)
  
  # Columna EDUCATION.
  ed.other = ifelse(x$EDUCATION == 4, 1,0)
  ed.university = ifelse(x$EDUCATION == 2, 1, 0)
  ed.high_school = ifelse(x$EDUCATION == 3 | x$EDUCATION == 2, 1, 0)
  ed.school = ifelse(x$EDUCATION == 1 | x$EDUCATION == 2 | x$EDUCATION == 3, 1, 0)
  x = cbind(x,ed.other, ed.high_school, ed.school, ed.university)

  # Borramos la columna EDUCATION.
  x = x[,-which(colnames(x) == "EDUCATION")]
  
  # Columna MARRIAGE.
  marriage.married = ifelse(x$MARRIAGE == 1, 1,0)
  marriage.single = ifelse(x$MARRIAGE == 2, 1,0)
  marriage.others = ifelse(x$MARRIAGE == 3, 1,0)
  
  # Introducimos los datos.
  x = cbind(x, marriage.married, marriage.single, marriage.others)
  
  # Borramos la variable MARRIAGE.
  x = x[, -which(colnames(x) == "MARRIAGE")]
  
  # Cambiamos el nombre de la variables PAY_0.
  colnames(x)[which(colnames(x)=="PAY_0")]="PAY_1"
  x
}

# Función que realiza la transformación BoxCox.
preprocesar = function(x,pred=trans){
  transTest = predict(pred, x)
  transTest
}

# Función que engloba las funciones anteriores.
prepareTest = function(x){
  tr = reemplazarCol(x)
  tr= preprocesar(x)
  tr
}
```

Por último, vamos a utilizar el filtro PCA para comprobar si todos los datos son relevantes. Si encontramos algún datos redundante , lo eliminaremos de nuestro conjunto de datos. Para saber si un dato es redundante, debemos comprobar si todos los atributos PC (PC1, PC2, ..., PCx) son 0 o muy cercanos a 0; si encontramos algún atributo PC que se aleje de 0, no podemos asegurar que el atributos sea redundante, y por lo tanto no lo podremos quitar.

```{r}
pcaTransformation = prcomp(trainTransformado[,-default.payment.next.month], center=F, scale=F)
pcaTransformation$rotation
```


Según los resultados del filtro PCA, no hay ningún dato que sea redundate. Por lo tanto, no eliminaremos ninguno de los atributos del conjunto de datos.

## Estudio de los parámetros e hiperparámetros.
Vamos a realizar un estudio sobre los parámetros para saber cuáles de ellos son los más importantes. Con los más importantes crearemos los modelos lineales que vamos a ajustar.

Con la función regsubsets, podemos encontrar que atributos son mejores a la hora de escogerlos antes.
```{r}
muestra_regsubsets = regsubsets(default.payment.next.month ~ ., data = trainTransformado, nvmax = 28, method = "exhaustive")
summary((muestra_regsubsets))
reg.sumary = summary(muestra_regsubsets)
```

Ahora, calcularemos los valores mínimos de los criterios cp y BIC. Utilizaremos estos dos valores para probar diferentes modelos.
```{r}
par(mfrow=c(1,2))
plot(reg.sumary$cp, xlab="number of variables", ylab="cp", type="l")
which.min(reg.sumary$cp)
plot(reg.sumary$bic, xlab="number of variables", ylab="BIC", type="l")
which.min(reg.sumary$bic)
par(mfrow=c(1,1) )
```

Según los resultados obtenidos, los dos mejores conjuntos de datos son de tamaño 17 y de tamaño 9. Tomaremos los atributos en el orden que aparecen en la salida de la función regsubsets.

## Modelos lineales.

Para hacer más sencillo el cálculo del error teniendo un modelo, crearemos funciones para calcular el error, para calcular el conjunto de datos precedidos, y otra que las englobe.


```{r}
# Función para calcular la solución dada una predicción.
calculateSol = function(x){
  prediction.model = rep(0,length(x))
  prediction.model[x >= 0.5] = 1
  
  prediction.model
}

# Función para calcular el Error.
calculateErrorClasification = function(calculated.solution, real.sol){
  er = sum(calculated.solution != real.sol)/length(calculated.solution)
  er
}

# Función que calcula el Error pasándole la predicción.
calculateError = function(model.prediction, labels){
  pred = calculateSol(model.prediction)
  return(calculateErrorClasification(pred, labels))
}
```

Transformamos los valores de test.
```{r}
testTransformado = reemplazarCol(credit_card.test)
testTransformado = predict(trans, testTransformado)
summary(testTransformado)
```

Ahora, pasaremos a probar diferentes modelos lineales. Para ello utilizaremos la función glm, que utiliza regresión logística. Una vez hecho esto, nos quedaremos con el modelo que menor error fuera de la muestra obtenga y que sea más sencillo. Calcularemos también el error dentro de la muestra para comprobar que ambos valores son cercanos y que no hay sobreajuste en el modelo.

Por último, calcularemos la curva ROC y el área del modelo que hayamos seleccionado.

```{r}
m1 = glm(default.payment.next.month~LIMIT_BAL+SEX+PAY_3+PAY_4+PAY_5+PAY_6+BILL_AMT1+BILL_AMT2+BILL_AMT3+PAY_AMT1+PAY_AMT2+PAY_AMT3+PAY_AMT3+PAY_AMT4+PAY_AMT5+PAY_AMT6+ed.other+ed.high_school+ed.school+ed.university+marriage.married+marriage.single, data=trainTransformado, family="binomial")

predtr.m1 = predict(m1, trainTransformado)
Ein.m1 = calculateError(predtr.m1, trainTransformado$default.payment.next.month)
Ein.m1

pred.m1 = predict(m1, testTransformado)
Eout.m1 = calculateError(pred.m1, testTransformado$default.payment.next.month)
Eout.m1
```



```{r}
m2 = glm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, family="binomial")
predtr.m2 = predict(m2, trainTransformado)
Ein.m2 = calculateError(predtr.m2, trainTransformado$default.payment.next.month)
Ein.m2

pred.m2 = predict(m2, testTransformado)
Eout.m2 = calculateError(pred.m2, testTransformado$default.payment.next.month)
Eout.m2
```




```{r}
m3= glm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, family="binomial" )
predtr.m3 = predict(m3, trainTransformado)
Ein.m3 = calculateError(predtr.m3, trainTransformado$default.payment.next.month)
Ein.m3

pred.m3 = predict(m3, testTransformado)
Eout.m3 = calculateError(pred.m3, testTransformado$default.payment.next.month)
Eout.m3
```

Nuestro mejor modelo es el tercer modelo, ya que es el más simple de los 3 y obtiene resultados casi iguales que los anteriores. La diferencia entre el error dentro de la muestra y fuera de la muestra son muy parecidos, por lo tanto, el modelo no presenta sobreajuste.Ahora pasaremos a calcular la curva ROC de este modelo, y también calcularemos el área de esta.

```{r}
linear.model = ROCR::prediction(pred.m3, testTransformado$default.payment.next.month)
perf = performance(linear.model, "tpr", "fpr")
auc.linear = performance(linear.model, measure = "auc")
print(auc.linear@y.values[[1]])
plot(perf)
```


## Modelos Boosting.
Para crear los modelos del boosting, utilizaremos la biblioteca ada, que contiene la función ada la cuál implementa el algoritmo adaboost. Uno de los parámetros de este algoritmo indica el número de clasficadores que se van a utilizar para separar los datos de la muestra; probaremos varios números de clasificadores. Nos quedaremos con el clasificador que menor error fuera de la muestra cometa. También calcularemos su curva ROC, y calcularemos cuál es el área de esta.

```{r}
bt1 = ada::ada(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, iter=10)
pred.bt1 = predict(bt1, trainTransformado)
Ein.bt1 = mean(pred.bt1 != trainTransformado$default.payment.next.month)
Ein.bt1

predTs.bt1 = predict(bt1, testTransformado)
Eout.bt1 = mean(predTs.bt1 != testTransformado$default.payment.next.month)
Eout.bt1
```

```{r}
bt2 = ada::ada(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, iter=30)
pred.bt2 = predict(bt2, trainTransformado)
Ein.bt2 = mean(pred.bt2 != trainTransformado$default.payment.next.month)
Ein.bt2

predTs.bt2 = predict(bt2, testTransformado)
Eout.bt2 = mean(predTs.bt2 != testTransformado$default.payment.next.month)
Eout.bt2
```


```{r}
bt3 = ada::ada(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, iter=5)
pred.bt3 = predict(bt3, trainTransformado)
Ein.bt3 = mean(pred.bt3 != trainTransformado$default.payment.next.month)
Ein.bt3

predTs.bt3 = predict(bt3, testTransformado)
Eout.bt3 = mean(predTs.bt3 != testTransformado$default.payment.next.month)
Eout.bt3
```


Como los errores son todos muy parecidos entre ellos, nos quedaremos con el modelo más sencillo, el cuál es el modelo 3; ya que es el que menos clasificadores utiliza.
Ahora calcularemos su curva ROC y el area debajo de esta.

```{r}
predi = predict(bt3, testTransformado, type = "probs")
salida.boosting = predi[,2]
boosting.model = ROCR::prediction(salida.boosting, testTransformado$default.payment.next.month)
perf.boost = performance(boosting.model, "tpr", "fpr")
auc.boosting = performance(boosting.model, measure = "auc")
print(auc.boosting@y.values[[1]])
plot(perf.boost)
```

## Modelos Redes Neuronales

Para crear los modelos del Redes Neuronales, utilizaremos la biblioteca neuralnet, que contiene la función neuralnet la cuál implementa el algoritmo backpropagation. Los parametros utilizados en este algoritmo son: hidden = indica el número de capas ocultas  y los nodos que contiene en cada capa que se van a utilizar para separar los datos de la muestra; probaremos con distintas capas; stepmax = fija el número máximo de pasos para el entrenamiento de las redes neuronales; threshold = es el umbral que limita el valor de las derivadas parciales de la función de error usandolo como criterio de parada. Nos quedaremos con la red que menor error fuera de la muestra cometa. También calcularemos su curva ROC, y calcularemos cuál es el área de esta.

```{r}
nn1 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = c(5,3,2), threshold = 0.8, stepmax = 1e+06)

plot(nn1)


n <- c("PAY_1", "PAY_2", "BILL_AMT1", "LIMIT_BAL","AGE","ed.school","PAY_AMT1","PAY_5","marriage.married")

pred.nn1 = compute(nn1, trainTransformado[names(trainTransformado) %in% n])

pred.nn1_ = pred.nn1$net.result*(max(pred.nn1$net.result)-min(pred.nn1$net.result))+min(pred.nn1$net.result)

calculateError(pred.nn1_,trainTransformado$default.payment.next.month)

pred.nn1Ts = compute(nn1, testTransformado[names(testTransformado) %in% n])

pred.nn1_test = pred.nn1Ts$net.result*(max(pred.nn1Ts$net.result)-min(pred.nn1Ts$net.result))+min(pred.nn1Ts$net.result)


calculateError(pred.nn1_test,testTransformado$default.payment.next.month)




```
```{r}
nn2 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = c(5,3), threshold = 0.5, stepmax = 1e+06)

plot(nn2)

pred.nn2 = compute(nn2, trainTransformado[names(trainTransformado) %in% n])

pred.nn2_ = pred.nn2$net.result*(max(pred.nn2$net.result)-min(pred.nn2$net.result))+min(pred.nn2$net.result)

calculateError(pred.nn2_,trainTransformado$default.payment.next.month)

pred.nn2Ts = compute(nn2, testTransformado[names(testTransformado) %in% n])

pred.nn2_test = pred.nn2Ts$net.result*(max(pred.nn2Ts$net.result)-min(pred.nn2Ts$net.result))+min(pred.nn2Ts$net.result)


calculateError(pred.nn2_test,testTransformado$default.payment.next.month)
```

```{r}
nn3 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = 5, threshold = 0.5, stepmax = 1e+06)

plot(nn3)

pred.nn3 = compute(nn3, trainTransformado[names(trainTransformado) %in% n])

pred.nn3_ = pred.nn3$net.result*(max(pred.nn3$net.result)-min(pred.nn3$net.result))+min(pred.nn3$net.result)

calculateError(pred.nn3_,trainTransformado$default.payment.next.month)

pred.nn3Ts = compute(nn3, testTransformado[names(testTransformado) %in% n])

pred.nn3_test = pred.nn3Ts$net.result*(max(pred.nn3Ts$net.result)-min(pred.nn3Ts$net.result))+min(pred.nn3Ts$net.result)


calculateError(pred.nn3_test,testTransformado$default.payment.next.month)
```

```{r}
nn4 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = c(3,2), threshold = 0.4, stepmax = 1e+06)
plot(nn4)

pred.nn4 = compute(nn4, trainTransformado[names(trainTransformado) %in% n])

pred.nn4_ = pred.nn4$net.result*(max(pred.nn4$net.result)-min(pred.nn4$net.result))+min(pred.nn4$net.result)

calculateError(pred.nn4_,trainTransformado$default.payment.next.month)

pred.nn4Ts = compute(nn4, testTransformado[names(testTransformado) %in% n])

pred.nn4_test = pred.nn4Ts$net.result*(max(pred.nn4Ts$net.result)-min(pred.nn4Ts$net.result))+min(pred.nn4Ts$net.result)


calculateError(pred.nn4_test,testTransformado$default.payment.next.month)
```

Podemos observar que los errores son casi iguales y se diferencian muy poco. Esto es debido a que por la necesidad de eficiencia en tiempo hemos aunmentado mucho el valor de la variable threshold, cuyo valor mejoraría bastante el error con un [0,1,0.01], lo que creemos que repercute en el error que comete. Dado que las redes neuronales necesitan mas tiempo de  entrenamiento que el que les hemos podido proporcionar. Por último creemos que los errores son muy parecidos entre los modelos puede ser debido, además de que el umbral threshold es muy alto, las capas ocultas son muy parecidas.

En este caso, el mejor modelo es el tercero, ya que es el que tiene una cantidad muy pequeña menos de error y consume menos tiempo de ejecución. Ahora calcularemos su curva ROC.

```{r}
probsnn = compute(nn3, testTransformado[names(testTransformado) %in% n])
probsnn.pred = probsnn$net.result
nn.model = ROCR::prediction(probsnn.pred, testTransformado$default.payment.next.month)
perfnn = performance(nn.model, "tpr", "fpr")
auc.nn = performance(nn.model, measure = "auc")
print(auc.nn@y.values[[1]])
plot(perfnn)

```

## Modelos con clasificador SVM.
Para utilizar el clasificador SVM, utilizaremos el paquete _e1071_, dentro de este se encuentra la función svm, esta por defecto utiliza un kernel gaussiano. La fórmula que utilizaremos será la misma que las anteriormente utilizadas. Probaremos con diferentes valores para este parámetro y nos quedaremos con el mejor de ellos.

Después, calcularemos la curva ROC del modeo elegido.

```{r}
svm1 = e1071::svm(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, gamma=0.1, type="C", tolerance=0.01)

pred.svm1 = predict(svm1, trainTransformado)
predTs.svm1 = predict(svm1, testTransformado)
Ein.svm1 = mean(pred.svm1 != trainTransformado$default.payment.next.month)
Eout.smv1 = mean(predTs.svm1 != testTransformado$default.payment.next.month)
Ein.svm1
Eout.svm1
```

```{r}
svm2 = e1071::svm(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, gamma=0.01, type="C", tolerance=0.01)

pred.svm2 = predict(svm2, trainTransformado)
predTs.svm2 = predict(svm2, testTransformado)
Ein.svm2 = mean(pred.svm2 != trainTransformado$default.payment.next.month)
Eout.smv2 = mean(predTs.svm2 != testTransformado$default.payment.next.month)
Ein.svm2
Eout.svm2
```

```{r}
svm3 = e1071::svm(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, gamma=1, type="C", tolerance=0.01)

pred.svm3 = predict(svm3, trainTransformado)
predTs.svm3 = predict(svm3, testTransformado)
Ein.svm3 = mean(pred.svm3 != trainTransformado$default.payment.next.month)
Eout.smv3 = mean(predTs.svm3 != testTransformado$default.payment.next.month)
Ein.svm3
Eout.svm3
```

```{r}
svm4 = e1071::svm(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, gamma=15, type="C", tolerance=0.01)

pred.svm4 = predict(svm4, trainTransformado)
predTs.svm4 = predict(svm4, testTransformado)
Ein.svm4 = mean(pred.svm4 != trainTransformado$default.payment.next.month)
Eout.smv4 = mean(predTs.svm4 != testTransformado$default.payment.next.month)
Ein.svm4
Eout.svm4
```

Para estos cuatro modelos, el mejor de todos ellos es el primero, ya que tiene el error fuera de la muestra más bajo. Además, la diferencia entre el error dentro de la muestra y el error fuera de la muestra no es grande por lo que sabemos que el modelo no tiene sobreajuste.

Ahora, calcularemos las probabilidades del modelo que hemos elegido y calcularemos su curva ROC y su área.


```{r}
s.svm = e1071::svm(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, gamma=0.1, type="C", tolerance=0.01, probability=T, decision.values=T)
pred.s = predict(s.svm, testTransformado, probability=T)
probs.svm = attr(pred.s, "probabilities")[,1]
svm.model = ROCR::prediction(probs.svm, testTransformado$default.payment.next.month)
perf = performance(svm.model, "tpr", "fpr")
auc.svm = performance(svm.model, measure = "auc")
print(auc.svm@y.values[[1]])
plot(perf)
```

## Modelos con randomForest
Para los modelos de Random Forest, utilizaremos la función randomForest. Utilizaremos diferentes valores para el número de árboles que usa este método; el número de nodos será siempre el mismo, 400. Una vez hayamos evaluado todos los modelos, elegiremos el que menor error fuera de la muestra cometa y calcularemos la curva ROC de este.

```{r}
n <- c("PAY_1", "PAY_2", "BILL_AMT1", "LIMIT_BAL","AGE","ed.school","PAY_AMT1","PAY_5","marriage.married")
rf = randomForest::randomForest(x=trainTransformado[, names(trainTransformado)%in%n], y=as.factor(trainTransformado$default.payment.next.month), data=trainTransformado, ntree=1000, maxnodes = 400)

pred.rf1 = predict(rf, trainTransformado)
Ein.rf1 = mean( pred.rf1 != trainTransformado$default.payment.next.month)
Ein.rf1

predTs.rf1 = predict(rf, testTransformado)
Eout.rf1 = mean( predTs.rf1 != testTransformado$default.payment.next.month)
Eout.rf1

```

```{r}
rf2 = randomForest::randomForest(x=trainTransformado[, names(trainTransformado)%in%n], y=as.factor(trainTransformado$default.payment.next.month), data=trainTransformado, ntree=1500, maxnodes = 400)

pred.rf2 = predict(rf2, trainTransformado)
Ein.rf2 = mean( pred.rf2 != trainTransformado$default.payment.next.month)
Ein.rf2

predTs.rf2 = predict(rf2, testTransformado)
Eout.rf2 = mean( predTs.rf2 != testTransformado$default.payment.next.month)
Eout.rf2

```

```{r}
rf3 = randomForest::randomForest(x=trainTransformado[, names(trainTransformado)%in%n], y=as.factor(trainTransformado$default.payment.next.month), data=trainTransformado, ntree=2000, maxnodes = 400)

pred.rf3 = predict(rf3, trainTransformado)
Ein.rf3 = mean( pred.rf3 != trainTransformado$default.payment.next.month)
Ein.rf3

predTs.rf3 = predict(rf3, testTransformado)
Eout.rf3 = mean( predTs.rf3 != testTransformado$default.payment.next.month)
Eout.rf3

```

El primer modelo es el mejor de los 3, ya que comete un error muy parecido al resto de los modelos utilizando menos árboles para ello. Ahora calcularemos la curva ROC y su área debajo de la curva.

```{r}
probs = predict(rf, testTransformado, type="prob")
probs.pred = probs[,2]
rf.model = ROCR::prediction(probs.pred, testTransformado$default.payment.next.month)
perf = performance(rf.model, "tpr", "fpr")
auc.rf = performance(rf.model, measure = "auc")
print(auc.rf@y.values[[1]])
plot(perf)


```

## Conclusiones.

Los resultados obtenidos por los clasificadores son los siguientes:

: Área debajo de la curva ROC
| Clasificador     | Área |
|------------------|------|
| Lineal           |0.7182|
| Boosting         |0.6797|
| SVM              |0.7062|
| Redes Neuronales |0.5492|
| Random Forest    |0.7523|

Como podemos ver, el clasificador que mejores resultados obtiene es el Random Forest, el siguiente mejor clasificador es el lineal. Por lo tanto el mejor modelo posible es el que utiliza Random Forest, pero el modelo lineal también obtiene bastante buenos resultados, por lo también podríamos considerar utilizar este modelo ya que es más sencillo.

Además, creemos que un modelo de redes neuronales con los parámetros adecuados, y con la el tiempo suficiente para entrenarlas; podría obtener unos resultados parecidos a los que se obtienen con el resto de los modelos.