---
title: "Proyecto Final"
author: 'Juan Alberto Martinez Lopez / Alberto Armijo Ruiz '
date: "27 de mayo de 2017"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Librerías utilizadas.
library("caret")
library("leaps")
library("e1071")
library("ROCR")
library("randomForest")
library("neuralnet")
library("ada")

set.seed(1)
```


## 1. default of credit card clients Data Set (Clasificación)

La base de datos se centra en el caso de los pagos por defecto de los clientes en Taiwán y compara la precisión predictiva de la probabilidad de incumplimiento entre seis métodos de minería de datos. Desde la perspectiva de la gestión de riesgos, el resultado de la precisión predictiva de la probabilidad estimada de incumplimiento será más valioso que el resultado binario de la clasificación - clientes creíbles o no creíbles. Con la probabilidad real de default como variable de respuesta (Y), y la probabilidad predictiva de default como variable independiente (X), el resultado de regresión lineal simple (Y = A + BX) muestra que el modelo de predicción producido por la red neuronal artificial tiene el mayor coeficiente de determinación. Su intercepción de regresión (A) es cercana a cero, y el coeficiente de regresión (B) a uno. Por lo tanto, entre las seis técnicas de minería de datos, la red neuronal artificial es la única que puede estimar con precisión la probabilidad real de incumplimiento. Dichas caracteristicas son:

Limit_bat: Cantidad de credito bancario dado(en dolares), incluye el credito individual y de su familia.
Sex: genero (0 = mujer, 1 = hombre).
Education: Educación recivida en 4 variables:
  Others: Otros estudios.
  University: Estudios universitarios.
  High school: Estudios preparatoria.
  school: Estudios básicos.
Marriage: Estado marital en 3 variables:
  Married: Casado.
  Single: soltero.
  Others: otros.
Age: Edad.
Pay_1-6: 
Historia del pago anterior. Seguimos los últimos registros de pagos mensuales (de abril a septiembre de 2005) de la siguiente manera: X6 = el estado de pago en septiembre de 2005; X7 = estado de reembolso en agosto de 2005; . . . X11 = el estado de pago en abril de 2005. La escala de medición para el estado de pago es: -1 = pagar debidamente; 1 = retraso de pago de un mes; 2 = retardo de pago por dos meses; . . Unesdoc.unesco.org unesdoc.unesco.org 8 = retardo de pago por ocho meses; 9 = retraso de pago por nueve meses y más.

Bill_Amt1-6: 
Monto del estado de cuenta (dólar NT). X12 = monto del estado de cuenta en septiembre de 2005; X13 = monto del estado de cuenta en agosto de 2005; . . . X17 = monto del estado de cuenta en abril de 2005.
Pay_Amt1-6:
Monto del pago anterior (dólar NT). X18 = cantidad pagada en septiembre de 2005; X19 = cantidad pagada en agosto de 2005; . . X23 = cantidad pagada en abril de 2005.
default payment next month: Variable que aprendemos, basamos si lapersona pagará o no el siguiente mes.


```{r} 
credit_card =  read.csv("default_of_credict_card_clients.csv"
                          , sep=",", header = TRUE, row.names =1)
attach(credit_card)
summary(credit_card)

```

```{r}
set.seed(1)
train = sample (nrow(credit_card), round(nrow(credit_card)*0.7)) 
credit_card.train = credit_card[train,]  
credit_card.test = credit_card[-train,]
```

## 2. Preprocesado de los datos.

Lo primero que queremos hacer es comprobar si hay datos perdidos, y si es así; reemplazaremos el valor perdido.
```{r}
anyNA(credit_card.train)
```
Como  no tenemos ningún dato pérdido, no tendremos que reemplazar los valores. Si hubieramos tenido valores tenido, podríamos haber utilizado la función _knnImputation_ para reemplazar los valores perdidos por los k vecinos mÃ¡s cercanos (normalmente k=3). TambiÃ©n podrÃ?amos utilizar la media como sustituto del valor pÃ©rdido.

Lo siguiente que vamos a hacer es modificar aquellas columnas que separan los datos en variables "clases" como por ejemplo la columna _EDUCATION_, que indica que tipo de estudios tiene cada persona. Por cada tipo en los que los separe, crearemos una nueva columna que indique con 0s y 1s la pertenencia a ese tipo. TambiÃ©n tenemos que realizar este proceso con la columna _MARRIAGE_

```{r}
# Modificamos la columna 2, llamada sex, para dividir los datos en 0=mujer, 1=hombre.
credit_card.train$SEX = ifelse(credit_card.train$SEX == 2, 0, 1)
summary(credit_card.train)
```
```{r}
# TambiÃ©n tenemos que modificar la columna EDUCATION, la dividiremos en cuatro columnas diferentes:
# ed.other, ed.university, ed.high_school, ed.school
ed.other = ifelse(credit_card.train$EDUCATION == 4, 1,0)
ed.university = ifelse(credit_card.train$EDUCATION == 2, 1, 0)
ed.high_school = ifelse(credit_card.train$EDUCATION == 3 | credit_card.train$EDUCATION == 2, 1, 0)
ed.school = ifelse(credit_card.train$EDUCATION == 1 | credit_card.train$EDUCATION == 2 | credit_card.train$EDUCATION == 3, 1, 0)

credit_card.train = cbind(credit_card.train,ed.other, ed.high_school, ed.school, ed.university)

# Borramos la columna EDUCATION.
credit_card.train = credit_card.train[,-which(colnames(credit_card.train) == "EDUCATION")]
summary(credit_card.train)
```

```{r}
# TambiÃ©n tenemos que modificar la columna mariage. Introduciremos tres nueva columnas: marriage.married, marriage.single, marriage.others.
marriage.married = ifelse(credit_card.train$MARRIAGE == 1, 1,0)
marriage.single = ifelse(credit_card.train$MARRIAGE == 2, 1,0)
marriage.others = ifelse(credit_card.train$MARRIAGE == 3, 1,0)

# Introducimos los datos.
credit_card.train = cbind(credit_card.train, marriage.married, marriage.single, marriage.others)

# Borramos la variable MARRIAGE.
credit_card.train = credit_card.train[, -which(colnames(credit_card.train) == "MARRIAGE")]
summary(credit_card.train)
```

TambiÃ©n vamos a cambiar el nombre de la columna _PAY0_ por _PAY1_.
```{r}
colnames(credit_card.train)[which(colnames(credit_card.train)=="PAY_0")]="PAY_1"
summary(credit_card.train)
```


Por Último.
```{r}
# Por Ãºltimo, utilizamos la funciÃ³n preprocess.
trans = preProcess(credit_card.train, c("BoxCox") )
trainTransformado = predict(trans, credit_card.train)
summary(trainTransformado)

```

  
```{r}
# Para hacer mÃ¡s sencillo hacer las transformaciones al conjunto de test, se crearÃ¡n funciones para realizar todo lo anterior.

# FunciÃ³n para comprobar si hay datos pÃ©rdidos y reemplazarlos.
reemplazarCol = function(x){
  # Columna SEX
  x$SEX = ifelse(x$SEX == 2, 0, 1)
  
  # Columna EDUCATION.
  ed.other = ifelse(x$EDUCATION == 4, 1,0)
  ed.university = ifelse(x$EDUCATION == 2, 1, 0)
  ed.high_school = ifelse(x$EDUCATION == 3 | x$EDUCATION == 2, 1, 0)
  ed.school = ifelse(x$EDUCATION == 1 | x$EDUCATION == 2 | x$EDUCATION == 3, 1, 0)
  x = cbind(x,ed.other, ed.high_school, ed.school, ed.university)

  # Borramos la columna EDUCATION.
  x = x[,-which(colnames(x) == "EDUCATION")]
  
  # Columna MARRIAGE.
  marriage.married = ifelse(x$MARRIAGE == 1, 1,0)
  marriage.single = ifelse(x$MARRIAGE == 2, 1,0)
  marriage.others = ifelse(x$MARRIAGE == 3, 1,0)
  
  # Introducimos los datos.
  x = cbind(x, marriage.married, marriage.single, marriage.others)
  
  # Borramos la variable MARRIAGE.
  x = x[, -which(colnames(x) == "MARRIAGE")]
  
  # Cambiamos el nombre de la variables PAY_0.
  colnames(x)[which(colnames(x)=="PAY_0")]="PAY_1"
  x
}

preprocesar = function(x,pred=trans){
  transTest = predict(pred, x)
  transTest
}

prepareTest = function(x){
  tr = reemplazarCol(x)
  tr= preprocesar(x)
  tr
}
```

Por último, vamos a utilizar el filtro PCA para comprobar si todos los datos son relevantes. Si encontramos algún datos redundante , lo eliminaremos de nuestro conjunto de datos. Para saber si un dato es redundante, debemos comprobar si todos los atributos PC (PC1, PC2, ..., PCx) son 0 o muy cercanos a 0; si encontramos algún atributo PC que se aleje de 0, no podemos asegurar que el atributos sea redundante, y por lo tanto no lo podremos quitar.

```{r}
pcaTransformation = prcomp(trainTransformado[,-default.payment.next.month], center=F, scale=F)
pcaTransformation$rotation
```


Según los resultados del filtro PCA, no hay ningún dato que sea redundate. Por lo tanto, no eliminaremos ninguno de los atributos del conjunto de datos.

## Estudio de los parámetros e hiperparámetros.
Vamos a realizar un estudio sobre los parámetros para saber cuáles de ellos son los más importantes. Con los más importantes crearemos los modelos lineales que vamos a ajustar.



```{r}
#modelo_step = glm(default.payment.next.month ~ .,family = gaussian, data=trainTransformado)
#modelo_principal = step(modelo_step)

```
Regsubset

```{r}
muestra_regsubsets = regsubsets(default.payment.next.month ~ ., data = trainTransformado, nvmax = 28, method = "exhaustive")
summary((muestra_regsubsets))
reg.sumary = summary(muestra_regsubsets)
```

```{r}
par(mfrow=c(1,2))
plot(reg.sumary$cp, xlab="number of variables", ylab="cp", type="l")
which.min(reg.sumary$cp)
plot(reg.sumary$bic, xlab="number of variables", ylab="BIC", type="l")
which.min(reg.sumary$bic)
par(mfrow=c(1,1) )
```



```{r}
variablesSignificativasCredit = character()

for(nombre in names(trainTransformado) ){
  pred = trainTransformado[, nombre]
  modelo = lm(trainTransformado$default.payment.next.month~pred)
  p_valor = summary(modelo)$coefficients[,4][2]
  
  if(p_valor < 0.1 && p_valor > 0){
    variablesSignificativasCredit = c(variablesSignificativasCredit, nombre)
  }
  
}

variablesSignificativasCredit
```

# Ajuste de modelos.

Para hacer más sencillo el cálculo del error teniendo un modelo, crearemos funciones para calcular el error, para calcular el conjunto de datos precedidos, y otra que las englobe.


```{r}
# Función para calcular la solución dada una predicción.
calculateSol = function(x){
  prediction.model = rep(0,length(x))
  prediction.model[x >= 0.5] = 1
  
  prediction.model
}

# Función para calcular el Error.
calculateErrorClasification = function(calculated.solution, real.sol){
  er = sum(calculated.solution != real.sol)/length(calculated.solution)
  er
}

# Función que calcula el Error pasándole la predicción.
calculateError = function(model.prediction, labels){
  pred = calculateSol(model.prediction)
  return(calculateErrorClasification(pred, labels))
}
```

Transformamos los valores de test.
```{r}
testTransformado = reemplazarCol(credit_card.test)
testTransformado = predict(trans, testTransformado)
dim(trainTransformado)
dim(testTransformado)
summary(testTransformado)
```


```{r}
m1 = glm(default.payment.next.month~LIMIT_BAL+SEX+PAY_3+PAY_4+PAY_5+PAY_6+BILL_AMT1+BILL_AMT2+BILL_AMT3+PAY_AMT1+PAY_AMT2+PAY_AMT3+PAY_AMT3+PAY_AMT4+PAY_AMT5+PAY_AMT6+ed.other+ed.high_school+ed.school+ed.university+marriage.married+marriage.single, data=trainTransformado, family="binomial")

predtr.m1 = predict(m1, trainTransformado)
Ein.m1 = calculateError(predtr.m1, trainTransformado$default.payment.next.month)
Ein.m1

pred.m1 = predict(m1, testTransformado)
Eout.m1 = calculateError(pred.m1, testTransformado$default.payment.next.month)
Eout.m1
```



```{r}
m2 = glm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, family="binomial")
predtr.m2 = predict(m2, trainTransformado)
Ein.m2 = calculateError(predtr.m2, trainTransformado$default.payment.next.month)
Ein.m2

pred.m2 = predict(m2, testTransformado)
Eout.m2 = calculateError(pred.m2, testTransformado$default.payment.next.month)
Eout.m2
```




```{r}
m3= glm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, family="binomial" )
predtr.m3 = predict(m3, trainTransformado)
Ein.m3 = calculateError(predtr.m3, trainTransformado$default.payment.next.month)
Ein.m3

pred.m3 = predict(m3, testTransformado)
Eout.m3 = calculateError(pred.m3, testTransformado$default.payment.next.month)
Eout.m3
```

Nuestro mejor modelo es el tercer modelo, ya que es el más simple de los 3 y obtiene resultados casi iguales que los anteriores. Calcularemos la curva ROC de este modelo, y también calcularemos el área de esta.

```{r}
linear.model = ROCR::prediction(pred.m3, testTransformado$default.payment.next.month)
perf = performance(linear.model, "tpr", "fpr")
auc.linear = performance(linear.model, measure = "auc")
print(auc.linear@y.values[[1]])
plot(perf)
```


## Modelos Boosting.
Para crear los modelos del boosting, utilizaremos la biblioteca fastAdaboost, que contiene la función adaboost la cuál implementa el algoritmo adaboost. Uno de los parámetros de este algoritmo indica el número de clasficadores que se van a utilizar para separar los datos de la muestra; probaremos varios números de clasificadores. Nos quedaremos con el clasificador que menor error fuera de la muestra cometa. También calcularemos su curva ROC, y calcularemos cuál es el área de esta.

```{r}
bt1 = ada::ada(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, iter=10)
pred.bt1 = predict(bt1, trainTransformado)
Ein.bt1 = mean(pred.bt1 != trainTransformado$default.payment.next.month)
Ein.bt1

predTs.bt1 = predict(bt1, testTransformado)
Eout.bt1 = mean(predTs.bt1 != testTransformado$default.payment.next.month)
Eout.bt1
```

```{r}
bt2 = ada::ada(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado, iter=50)
pred.bt2 = predict(bt2, trainTransformado)
Ein.bt2 = mean(pred.bt2 != trainTransformado$default.payment.next.month)
Ein.bt2

predTs.bt2 = predict(bt2, testTransformado)
Eout.bt2 = mean(predTs.bt2 != testTransformado$default.payment.next.month)
Eout.bt2
```


```{r}
bt3 = ada::ada(formula=default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, iter=5)
pred.bt3 = predict(bt3, trainTransformado)
Ein.bt3 = mean(pred.bt3 != trainTransformado$default.payment.next.month)
Ein.bt3

predTs.bt3 = predict(bt3, testTransformado)
Eout.bt3 = mean(predTs.bt3 != testTransformado$default.payment.next.month)
Eout.bt3
```

```{r}
bt4 = ada::ada(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, iter=10)
pred.bt4 = predict(bt4, trainTransformado)
Ein.bt4 = mean( pred.bt4 != trainTransformado$default.payment.next.month )
Ein.bt4

predTs.bt4 = predict(bt4, testTransformado)
Eout.bt4 = mean( predTs.bt4 != testTransformado$default.payment.next.month )
Eout.bt4
```

```{r}
bt5 = ada::ada(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, iter=50)
pred.bt5 = predict(bt5, trainTransformado)
Ein.bt5 = mean( pred.bt5 != trainTransformado$default.payment.next.month )
Ein.bt5

predTs.bt5 = predict(bt5, testTransformado)
Eout.bt5 = mean( predTs.bt5 != testTransformado$default.payment.next.month )
Eout.bt5
```


```{r}
bt6 = ada::ada(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married+PAY_3+SEX+PAY_AMT2+ed.high_school+PAY_AMT4+marriage.single+marriage.others+BILL_AMT2,data=trainTransformado, iter=5)
pred.bt6 = predict(bt6, trainTransformado)
Ein.bt6 = mean( pred.bt6 != trainTransformado$default.payment.next.month)
Ein.bt6

predTs.bt6 = predict(bt6, testTransformado)
Eout.bt6 = mean( predTs.bt6 != testTransformado$default.payment.next.month )
Eout.bt6
```

Como los errores son todos muy parecidos entre ellos, nos quedaremos con el modelo más sencillo, el cuál es el modelo 3.
Ahora calcularemos su curva ROC y el area debajo de esta.

```{r}
print(table(predTs.bt3, testTransformado$default.payment.next.month))
```

```{r}
predi = predict(bt3, testTransformado, type = "probs")
salida.boosting = predi[,2]
boosting.model = ROCR::prediction(salida.boosting, testTransformado$default.payment.next.month)
perf.boost = performance(boosting.model, "tpr", "fpr")
auc.boosting = performance(boosting.model, measure = "auc")
print(auc.boosting@y.values[[1]])
plot(perf.boost)
```

## Modelos Redes Neuronales

Para crear los modelos del Redes Neuronales, utilizaremos la biblioteca neuralnet, que contiene la función neuralnet la cuál implementa el algoritmo backpropagation. Los parametros utilizados en este algoritmo son: hidden = indica el número de capas ocultas  y los nodos que contiene en cada capa que se van a utilizar para separar los datos de la muestra; probaremos con distintas capas; stepmax = fija el número máximo de pasos para el entrenamiento de las redes neuronales; threshold = es el umbral que limita el valor de las derivadas parciales de la función de error usandolo como criterio de parada. Nos quedaremos con la red que menor error fuera de la muestra cometa. También calcularemos su curva ROC, y calcularemos cuál es el área de esta.

```{r}
nn1 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = c(5,3,2), threshold = 0.8, stepmax = 1e+06)

plot(nn1)


n <- c("PAY_1", "PAY_2", "BILL_AMT1", "LIMIT_BAL","AGE","ed.school","PAY_AMT1","PAY_5","marriage.married")

pred.nn1 = compute(nn1, trainTransformado[names(trainTransformado) %in% n])

pred.nn1_ = pred.nn1$net.result*(max(pred.nn1$net.result)-min(pred.nn1$net.result))+min(pred.nn1$net.result)

calculateError(pred.nn1_,trainTransformado$default.payment.next.month)

pred.nn1Ts = compute(nn1, testTransformado[names(testTransformado) %in% n])

pred.nn1_test = pred.nn1Ts$net.result*(max(pred.nn1Ts$net.result)-min(pred.nn1Ts$net.result))+min(pred.nn1Ts$net.result)


calculateError(pred.nn1_test,testTransformado$default.payment.next.month)




```
```{r}
nn2 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = c(5,3), threshold = 0.5, stepmax = 1e+06)

plot(nn2)

pred.nn2 = compute(nn2, trainTransformado[names(trainTransformado) %in% n])

pred.nn2_ = pred.nn2$net.result*(max(pred.nn2$net.result)-min(pred.nn2$net.result))+min(pred.nn2$net.result)

calculateError(pred.nn2_,trainTransformado$default.payment.next.month)

pred.nn2Ts = compute(nn2, testTransformado[names(testTransformado) %in% n])

pred.nn2_test = pred.nn2Ts$net.result*(max(pred.nn2Ts$net.result)-min(pred.nn2Ts$net.result))+min(pred.nn2Ts$net.result)


calculateError(pred.nn2_test,testTransformado$default.payment.next.month)
```

```{r}
nn3 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = 5, threshold = 0.5, stepmax = 1e+06)

plot(nn3)

pred.nn3 = compute(nn3, trainTransformado[names(trainTransformado) %in% n])

pred.nn3_ = pred.nn3$net.result*(max(pred.nn3$net.result)-min(pred.nn3$net.result))+min(pred.nn3$net.result)

calculateError(pred.nn3_,trainTransformado$default.payment.next.month)

pred.nn3Ts = compute(nn3, testTransformado[names(testTransformado) %in% n])

pred.nn3_test = pred.nn3Ts$net.result*(max(pred.nn3Ts$net.result)-min(pred.nn3Ts$net.result))+min(pred.nn3Ts$net.result)


calculateError(pred.nn3_test,testTransformado$default.payment.next.month)
```

```{r}
nn4 = neuralnet(formula = default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married,data=trainTransformado,hidden = c(3,2), threshold = 0.4, stepmax = 1e+06)
plot(nn4)

pred.nn4 = compute(nn4, trainTransformado[names(trainTransformado) %in% n])

pred.nn4_ = pred.nn4$net.result*(max(pred.nn4$net.result)-min(pred.nn4$net.result))+min(pred.nn4$net.result)

calculateError(pred.nn4_,trainTransformado$default.payment.next.month)

pred.nn4Ts = compute(nn4, testTransformado[names(testTransformado) %in% n])

pred.nn4_test = pred.nn4Ts$net.result*(max(pred.nn4Ts$net.result)-min(pred.nn4Ts$net.result))+min(pred.nn4Ts$net.result)


calculateError(pred.nn4_test,testTransformado$default.payment.next.month)
```

Podemos observar que los errores son casi iguales y se diferencian muy poco. Esto es debido a que por la necesidad de eficiencia en tiempo hemos aunmentado mucho el valor de la variable threshold, cuyo valor mejoraría bastante el error con un [0,1,0.01], lo que creemos que repercute en el error que comete. Dado que las redes neuronales necesitan mas tiempo de  entrenamiento que el que les hemos podido proporcionar. Por último creemos que los errores son muy parecidos entre los modelos puede ser debido, además de que el umbral threshold es muy alto, las capas ocultas son muy parecidas.

En este caso, el mejor modelo es el tercero, ya que es el que tiene una cantidad muy pequeña menos de error y consume menos tiempo de ejecución. Ahora calcularemos su curva ROC.

```{r}
probsnn = compute(nn3, testTransformado[names(testTransformado) %in% n])
probsnn.pred = probsnn$net.result
nn.model = ROCR::prediction(probsnn.pred, testTransformado$default.payment.next.month)
perfnn = performance(nn.model, "tpr", "fpr")
auc.nn = performance(nn.model, measure = "auc")
print(auc.nn@y.values[[1]])
plot(perfnn)

```

## Modelos con clasificador SVM.
Para utilizar el clasificador SVM, utilizaremos el paquete _e1071_, dentro de este se encuentra la función svm, esta por defecto utiliza un kernel radial. La fórmula que utilizaremos será la misma que las anteriormente utilizadas. Probaremos con diferentes valores para este argumento y nos quedaremos con el mejor de ellos.

Después, calcularemos la curva ROC del modeo elegido.
```{r}
svm1 = e1071::svm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, type="C" )
summary(svm1)

pred.svm1 = predict(svm1, trainTransformado)
predTs.svm1 = predict(svm1, testTransformado)

Ein.svm1 = mean( pred.svm1 != trainTransformado$default.payment.next.month )
Eout.svm1 = mean(predTs.svm1 != testTransformado$default.payment.next.month)
Ein.svm1
Eout.svm1
```

```{r}
svm2 = e1071::svm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado , gamma=0.5, type="C")


pred.svm2 = predict(svm2, trainTransformado)
predTs.svm2 = predict(svm2, testTransformado)

Ein.svm2 = mean(pred.svm2 != trainTransformado$default.payment.next.month)
Eout.svm2 = mean(predTs.svm2 != testTransformado$default.payment.next.month)
Ein.svm2
Eout.svm2
```


```{r}
svm3 = e1071::svm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado , gamma=0.01, type="C", probability=TRUE)


pred.svm3 = predict(svm3, trainTransformado)
predTs.svm3 = predict(svm3, testTransformado, decision.values=T)
salida = predict(svm3, testTransformado, type="class")

Ein.svm3 = mean(pred.svm3 != trainTransformado$default.payment.next.month)
Eout.svm3 = mean(salida != testTransformado$default.payment.next.month)
Ein.svm3
Eout.svm3
```

```{r}
svm4 = e1071::svm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado , gamma=2, type="C")


pred.svm4 = predict(svm4, trainTransformado)
predTs.svm4 = predict(svm4, testTransformado)

Ein.svm4 = mean(pred.svm4 != trainTransformado$default.payment.next.month)
Eout.svm4 = mean(predTs.svm4 != testTransformado$default.payment.next.month)
Ein.svm4
Eout.svm4
```

```{r}
svm5 = e1071::svm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado , gamma=15, type="C")


pred.svm5 = predict(svm5, trainTransformado)
predTs.svm5 = predict(svm5, testTransformado)

Ein.svm5 = mean(pred.svm5 != trainTransformado$default.payment.next.month)
Eout.svm5 = mean(predTs.svm5 !=  testTransformado$default.payment.next.month)
Ein.svm5
Eout.svm5
```

En este caso, el mejor modelo es el tercero, ya que es el que tiene un error fuera de la muestra menor. Ahora calcularemos su curva ROC.

### Comprobación parámetros cost.
```{r}
costs = c(1, 0.1, 10, 0.01)
best.err = 1
best.cost = 1
for(i in costs){
  my.model = e1071::svm(default.payment.next.month~PAY_1+PAY_2+BILL_AMT1+LIMIT_BAL+AGE+ed.school+PAY_AMT1+PAY_5+marriage.married, data=trainTransformado, type="C", cost=i)
  model.predition = predict(my.model, testTransformado)
  out.err = mean( model.predition != testTransformado$default.payment.next.month )
  print("Mejor error: ")
  print(best.err)
  print("Coste actual: ")
  print(out.err)
  if(out.err < best.err){
    best.err = out.err
    best.cost = i
  }
}

print("Mejor Coste: ")
print(best.cost)
```


```{r}
s.svm = attr(predTs.svm3, "decision.values")
svm.model = ROCR::prediction(s.svm, testTransformado$default.payment.next.month)
perf = performance(svm.model, "tpr", "fpr")
auc.svm = performance(svm.model, measure = "auc")
print(auc.svm@y.values[[1]])
plot(perf)
```

## Modelos con randomForest

```{r}
n <- c("PAY_1", "PAY_2", "BILL_AMT1", "LIMIT_BAL","AGE","ed.school","PAY_AMT1","PAY_5","marriage.married")
rf = randomForest::randomForest(x=trainTransformado[, names(trainTransformado)%in%n], y=as.factor(trainTransformado$default.payment.next.month), data=trainTransformado, ntree=1000, maxnodes = 400)

pred.rf1 = predict(rf, trainTransformado)
Ein.rf1 = mean( pred.rf1 != trainTransformado$default.payment.next.month)
Ein.rf1

predTs.rf1 = predict(rf, testTransformado)
Eout.rf1 = mean( predTs.rf1 != testTransformado$default.payment.next.month)
Eout.rf1

```

```{r}
rf2 = randomForest::randomForest(x=trainTransformado[, names(trainTransformado)%in%n], y=as.factor(trainTransformado$default.payment.next.month), data=trainTransformado, ntree=1500, maxnodes = 400)

pred.rf2 = predict(rf2, trainTransformado)
Ein.rf2 = mean( pred.rf2 != trainTransformado$default.payment.next.month)
Ein.rf2

predTs.rf2 = predict(rf2, testTransformado)
Eout.rf2 = mean( predTs.rf2 != testTransformado$default.payment.next.month)
Eout.rf2

```

```{r}
rf3 = randomForest::randomForest(x=trainTransformado[, names(trainTransformado)%in%n], y=as.factor(trainTransformado$default.payment.next.month), data=trainTransformado, ntree=2000, maxnodes = 400)

pred.rf3 = predict(rf3, trainTransformado)
Ein.rf3 = mean( pred.rf3 != trainTransformado$default.payment.next.month)
Ein.rf3

predTs.rf3 = predict(rf3, testTransformado)
Eout.rf3 = mean( predTs.rf3 != testTransformado$default.payment.next.month)
Eout.rf3

```

Ahora calcularemos la curva ROC.Tomaremos como mejor modelo el primero, que es el que menos árboles tiene que crear.

```{r}
probs = predict(rf, testTransformado, type="prob")
probs.pred = probs[,2]
rf.model = ROCR::prediction(probs.pred, testTransformado$default.payment.next.month)
perf = performance(rf.model, "tpr", "fpr")
auc.rf = performance(rf.model, measure = "auc")
print(auc.rf@y.values[[1]])
plot(perf)


```

